\documentclass[11pt]{article}

\begin{document}

\begin{quotation}
					Rahul Aditya
	
\end{quotation}

\begin{quotation}
					N16057067
\end{quotation}

\begin{quotation}
					adi.rahul171294@gmail.com
\end{quotation}

\begin{quotation}
					6th april 2016
\end{quotation}
	
WORD SENSE DISAMBIGUATION: UNSUPERVISED


Word Sense Disambiguation (WSD) is related to Natural Language Processing and computational languages. It came into being when people felt the need of machine translation, information retrieval, speech processing and text processing etc. The use of WSD is focused on determining the sense of word which is used in a problem by using that word in a particular context. Despite a greater number of existing disambiguation algorithms , WSD still has an open problem with the three main parts of the WSD methods being considered by literature: supervised, unsupervised and knowledge based disambiguation.
With the use of the Naive Bayes model, we can focus on the approaches to unsupervised WSD that rely on single writings. In this model, a number of sentences are used which contains a particular word which has several meanings. The main goal is to divide those words into a specified number of sense groups.
The Naive Bayes model applied mathematically entirely focuses on the issue of feature selection, which describes its two types:
1. Pedersen and Bruce local type features.
2. WordNet-based feature selection.
Apart from the above mentioned model, the web can act as a corpus too, where it searches words which are relevant and distinctive for the target word.
So, this background focuses mainly on the issues of feature selection for unsupervised WSD performed with an underlying Naive Bayes model.

\section{REFERENCES}


[1] D.Preotiuc-Pietro.2012.Unsupervised Word Sense Disambiguation with N-gram features.241-244,249,251,259. 



\end{document}