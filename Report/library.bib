Automatically generated by Mendeley Desktop 1.15.3
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Gabrilovich:2007:HEH:1314498.1314573,
author = {Gabrilovich, Evgeniy and Markovitch, Shaul},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
pages = {2297--2345},
publisher = {JMLR.org},
title = {{Harnessing the Expertise of 70,000 Human Editors: Knowledge-Based Feature Generation for Text Categorization}},
url = {http://dl.acm.org/citation.cfm?id=1314498.1314573},
volume = {8},
year = {2007}
}
@article{ISI:000295620300006,
abstract = {This article is centred on analysing the state of the art of the
conflation processes applied to geospatial databases (GDBs) from
heterogeneous sources. The term conflation is used to describe the
procedure for the integration of these different data, and conflation
methods play an important role in systems for updating GDBs, derivation
of new cartographic products, densification of digital elevation models,
automatic features extraction and so on. In this article we define
extensively each conflation process, its evaluation measures and its
main application problems and present a classification of all conflation
processes. Finally, we introduce a bibliography which the reader may
find useful to further explore the field. It tries to serve as a
starting point and direct the reader to characteristic research in this
area.},
address = {4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND},
author = {Ruiz, Juan J and Ariza, F Javier and Urena, Manuel A and Blazquez, Elidia B},
doi = {10.1080/13658816.2010.519707},
issn = {1365-8816},
journal = {INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE},
keywords = {conflation; data fusion; data integration; interop},
number = {9},
pages = {1439--1466},
publisher = {TAYLOR {\&} FRANCIS LTD},
title = {{Digital map conflation: a review of the process and a proposal for classification}},
type = {Review},
volume = {25},
year = {2011}
}
@misc{Liu2012,
abstract = {Currently available web news retrieval systems face a number of problems in that web-based news retrieval requires the ability to quickly and accurately process and update a very large amount of data which are constantly being updated. In this paper, we present the development of an intelligent distributed web news retrieval system the goal of which is to accurately retrieve and organize the web news information. It includes: a novel optimized crawler algorithm whose fetching-speed is several times faster than that of the traditional crawler; a keen tag based extraction algorithm which can extract the data rich content with minimal manual effort and which also allows data to be classified as important or not important so that the crawler can revisit and update important data; a modified MapReduce improved by estimating the execution time of each subtask, which is proven to be able to reduce the number of the unusual tasks and shorten the whole job execution time. © 2012 - IOS Press and the authors. All rights reserved.},
author = {Liu, James N K and Choi, K. C. and Chai, J. Y.},
booktitle = {International Journal of Knowledge-Based and Intelligent Engineering Systems},
doi = {10.3233/KES-2011-0237},
issn = {13272314},
keywords = {Intelligent system,MapReduce,distributed news retrieval,web crawler},
number = {2},
pages = {129--140},
title = {{Development of an intelligent distributed news retrieval system}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84861465913{\&}partnerID=tZOtx3y1},
volume = {16},
year = {2012}
}
@article{Du2013,
abstract = {With the Internet growing exponentially, search engines are encountering unprecedented challenges. A focused search engine selectively seeks out web pages that are relevant to user topics. Determining the best strategy to utilize a focused search is a crucial and popular research topic. At present, the rank values of unvisited web pages are computed by considering the hyperlinks (as in the PageRank algorithm), a Vector Space Model and a combination of them, and not by considering the semantic relations between the user topic and unvisited web pages. In this paper, we propose a concept context graph to store the knowledge context based on the user's history of clicked web pages and to guide a focused crawler for the next crawling. The concept context graph provides a novel semantic ranking to guide the web crawler in order to retrieve highly relevant web pages on the user's topic. By computing the concept distance and concept similarity among the concepts of the concept context graph and by matching unvisited web pages with the concept context graph, we compute the rank values of the unvisited web pages to pick out the relevant hyperlinks. Additionally, we constitute the focused crawling system, and we retrieve the precision, recall, average harvest rate, and F-measure of our proposed approach, using Breadth First, Cosine Similarity, the Link Context Graph and the Relevancy Context Graph. The results show that our proposed method outperforms other methods. © 2013 Elsevier B.V. All rights reserved.},
author = {Du, YaJun and Pen, QiangQiang and Gao, ZhaoQiong},
doi = {10.1016/j.datak.2013.09.003},
issn = {0169023X},
journal = {Data {\&} Knowledge Engineering},
keywords = {Concept context graph,Focused crawling,Formal concept analysis,Information retrieval,Search engine,Web crawler,Web information systems},
month = {nov},
pages = {75--93},
title = {{A topic-specific crawling strategy based on semantics similarity}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84889100636{\&}partnerID=tZOtx3y1},
volume = {88},
year = {2013}
}
@article{Martinez-Cruz2011,
abstract = {Two main data models are currently used for representing knowledge and information in computer systems. Database models, especially relational databases, have been the leader in last few decades, enabling information to be efficiently stored and queried. On the other hand, ontologies have appeared as an alternative to databases in applications that require a more 'enriched' meaning. However, there is controversy regarding the best information modeling technique, as both models present similar characteristics. In this paper, we present a review of how ontologies and databases are related, of what their main differences are and of the mechanisms used to communicate with each other. © Springer Science+Business Media B.V. 2011.},
author = {Martinez-Cruz, Carmen and Blanco, Ignacio J. and Vila, M. Amparo},
doi = {10.1007/s10462-011-9251-9},
issn = {0269-2821},
journal = {Artificial Intelligence Review},
keywords = {Ontologies,Ontology-based databases,Relational databases},
month = {jun},
number = {4},
pages = {271--290},
title = {{Ontologies versus relational databases: are they so different? A comparison}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84870244777{\&}partnerID=tZOtx3y1},
volume = {38},
year = {2011}
}
@article{ISI:000253400700005,
author = {Theobald, Martin and Bast, Holger and Majumdar, Debapriyo and Schenkel, Ralf and Weikum, Gerhard},
doi = {10.1007/s00778-007-0072-z},
issn = {1066-8888},
journal = {VLDB JOURNAL},
number = {1},
pages = {81--115},
title = {{TopX: efficient and versatile top-k query processing for semistructured data}},
volume = {17},
year = {2008}
}
