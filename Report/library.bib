Automatically generated by Mendeley Desktop 1.15.3
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Martinez-Cruz2011,
abstract = {Two main data models are currently used for representing knowledge and information in computer systems. Database models, especially relational databases, have been the leader in last few decades, enabling information to be efficiently stored and queried. On the other hand, ontologies have appeared as an alternative to databases in applications that require a more 'enriched' meaning. However, there is controversy regarding the best information modeling technique, as both models present similar characteristics. In this paper, we present a review of how ontologies and databases are related, of what their main differences are and of the mechanisms used to communicate with each other. © Springer Science+Business Media B.V. 2011.},
author = {Martinez-Cruz, Carmen and Blanco, Ignacio J. and Vila, M. Amparo},
doi = {10.1007/s10462-011-9251-9},
issn = {0269-2821},
journal = {Artificial Intelligence Review},
keywords = {Ontologies,Ontology-based databases,Relational databases},
month = {jun},
number = {4},
pages = {271--290},
title = {{Ontologies versus relational databases: are they so different? A comparison}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84870244777{\&}partnerID=tZOtx3y1},
volume = {38},
year = {2011}
}
@misc{Liu2012,
abstract = {Currently available web news retrieval systems face a number of problems in that web-based news retrieval requires the ability to quickly and accurately process and update a very large amount of data which are constantly being updated. In this paper, we present the development of an intelligent distributed web news retrieval system the goal of which is to accurately retrieve and organize the web news information. It includes: a novel optimized crawler algorithm whose fetching-speed is several times faster than that of the traditional crawler; a keen tag based extraction algorithm which can extract the data rich content with minimal manual effort and which also allows data to be classified as important or not important so that the crawler can revisit and update important data; a modified MapReduce improved by estimating the execution time of each subtask, which is proven to be able to reduce the number of the unusual tasks and shorten the whole job execution time. © 2012 - IOS Press and the authors. All rights reserved.},
author = {Liu, James N K and Choi, K. C. and Chai, J. Y.},
booktitle = {International Journal of Knowledge-Based and Intelligent Engineering Systems},
doi = {10.3233/KES-2011-0237},
issn = {13272314},
keywords = {Intelligent system,MapReduce,distributed news retrieval,web crawler},
number = {2},
pages = {129--140},
title = {{Development of an intelligent distributed news retrieval system}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84861465913{\&}partnerID=tZOtx3y1},
volume = {16},
year = {2012}
}
@article{Du2013,
abstract = {With the Internet growing exponentially, search engines are encountering unprecedented challenges. A focused search engine selectively seeks out web pages that are relevant to user topics. Determining the best strategy to utilize a focused search is a crucial and popular research topic. At present, the rank values of unvisited web pages are computed by considering the hyperlinks (as in the PageRank algorithm), a Vector Space Model and a combination of them, and not by considering the semantic relations between the user topic and unvisited web pages. In this paper, we propose a concept context graph to store the knowledge context based on the user's history of clicked web pages and to guide a focused crawler for the next crawling. The concept context graph provides a novel semantic ranking to guide the web crawler in order to retrieve highly relevant web pages on the user's topic. By computing the concept distance and concept similarity among the concepts of the concept context graph and by matching unvisited web pages with the concept context graph, we compute the rank values of the unvisited web pages to pick out the relevant hyperlinks. Additionally, we constitute the focused crawling system, and we retrieve the precision, recall, average harvest rate, and F-measure of our proposed approach, using Breadth First, Cosine Similarity, the Link Context Graph and the Relevancy Context Graph. The results show that our proposed method outperforms other methods. © 2013 Elsevier B.V. All rights reserved.},
author = {Du, YaJun and Pen, QiangQiang and Gao, ZhaoQiong},
doi = {10.1016/j.datak.2013.09.003},
issn = {0169023X},
journal = {Data {\&} Knowledge Engineering},
keywords = {Concept context graph,Focused crawling,Formal concept analysis,Information retrieval,Search engine,Web crawler,Web information systems},
month = {nov},
pages = {75--93},
title = {{A topic-specific crawling strategy based on semantics similarity}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84889100636{\&}partnerID=tZOtx3y1},
volume = {88},
year = {2013}
}
