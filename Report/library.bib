Automatically generated by Mendeley Desktop 1.15.3
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Mammen2016,
abstract = {Indian classical music, including its two varieties, Carnatic and Hindustani music, has a rich music tradition and enjoys a wide audience from various parts of the world. The Carnatic music which is more popular in South India still continues to be uninfluenced by other music traditions and is one of the purest forms of Indian music. Like other music traditions, Carnatic music also has developed its musicography, out of which, a notation system called Sargam is most commonly practiced. This paper deals with development of a music representation or encoding system for the Sargam notation scheme which enables easy music notation storage, publishing, and retrieval using computers. This work follows a novel idea of developing a Unicode-based encoding logic and allows storage and easy retrieval of music notation files in a computer. As opposed to many existing music representation systems for western music notation, iSargam is the only music notation encoding system developed for Indian music notation.},
author = {Mammen, Stanly and Krishnamurthi, Ilango and Varma, A. Jalaja and Sujatha, G.},
doi = {10.1186/s13636-016-0083-z},
issn = {1687-4722},
journal = {EURASIP Journal on Audio, Speech, and Music Processing},
keywords = {Computer music,Indian music,Music encoding,Music information retrieval,Music processing,Music representation},
month = {feb},
number = {1},
pages = {5},
publisher = {Springer International Publishing},
title = {{iSargam: music notation representation for Indian Carnatic music}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84958760963{\&}partnerID=tZOtx3y1},
volume = {2016},
year = {2016}
}
@article{Blascheck2016,
abstract = {Evaluation has become a fundamental part of visualization research and researchers have employed many approaches from the field of human-computer interaction like measures of task performance, thinking aloud protocols, and analysis of interaction logs. Recently, eye tracking has also become popular to analyze visual strategies of users in this context. This has added another modality and more data, which requires special visualization techniques to analyze this data. However, only few approaches exist that aim at an integrated analysis of multiple concurrent evaluation procedures. The variety, complexity, and sheer amount of such coupled multi-source data streams require a visual analytics approach. Our approach provides a highly interactive visualization environment to display and analyze thinking aloud, interaction, and eye movement data in close relation. Automatic pattern finding algorithms allow an efficient exploratory search and support the reasoning process to derive common eye-interaction-thinking patterns between participants. In addition, our tool equips researchers with mechanisms for searching and verifying expected usage patterns. We apply our approach to a user study involving a visual analytics application and we discuss insights gained from this joint analysis. We anticipate our approach to be applicable to other combinations of evaluation techniques and a broad class of visualization applications.},
author = {Blascheck, Tanja and John, Markus and Kurzhals, Kuno and Koch, Steffen and Ertl, Thomas},
doi = {10.1109/TVCG.2015.2467871},
issn = {1941-0506},
journal = {IEEE transactions on visualization and computer graphics},
keywords = {Data visualization,Gaze tracking,Navigation,Protocols,Synchronization,Visual analytics},
number = {1},
pages = {61--70},
pmid = {26529687},
publisher = {IEEE Computer Society},
title = {{A Visual Analytics Approach for // Evaluating Visual Analytics Applications.}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84946616161{\{}{\&}{\}}partnerID=tZOtx3y1},
volume = {22},
year = {2016}
}
@article{Gabrilovich:2007:HEH:1314498.1314573,
author = {Gabrilovich, Evgeniy and Markovitch, Shaul},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
pages = {2297--2345},
publisher = {JMLR.org},
title = {{Harnessing the Expertise of 70,000 Human Editors: Knowledge-Based Feature Generation for Text Categorization}},
url = {http://dl.acm.org/citation.cfm?id=1314498.1314573},
volume = {8},
year = {2007}
}
@misc{Liu2012,
abstract = {Currently available web news retrieval systems face a number of problems in that web-based news retrieval requires the ability to quickly and accurately process and update a very large amount of data which are constantly being updated. In this paper, we present the development of an intelligent distributed web news retrieval system the goal of which is to accurately retrieve and organize the web news information. It includes: a novel optimized crawler algorithm whose fetching-speed is several times faster than that of the traditional crawler; a keen tag based extraction algorithm which can extract the data rich content with minimal manual effort and which also allows data to be classified as important or not important so that the crawler can revisit and update important data; a modified MapReduce improved by estimating the execution time of each subtask, which is proven to be able to reduce the number of the unusual tasks and shorten the whole job execution time. © 2012 - IOS Press and the authors. All rights reserved.},
author = {Liu, James N K and Choi, K C and Chai, J Y},
booktitle = {International Journal of Knowledge-Based and Intelligent Engineering Systems},
doi = {10.3233/KES-2011-0237},
issn = {13272314},
keywords = {Intelligent system,MapReduce,distributed news retrieval,web crawler},
number = {2},
pages = {129--140},
title = {{Development of an intelligent distributed news retrieval system}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84861465913{\{}{\&}{\}}partnerID=tZOtx3y1},
volume = {16},
year = {2012}
}
@article{Szpunar2010,
abstract = {The ability to mentally simulate hypothetical scenarios is a rapidly growing area of research in both psychology and neuroscience. Episodic future thought, or the ability to simulate specific personal episodes that may potentially occur in the future, represents one facet of this general capacity that continues to garner a considerable amount of interest. The purpose of this article is to elucidate current knowledge and identify a number of unresolved issues regarding this specific mental ability. In particular, this article focuses on recent research findings from neuroimaging, neuropsychology, and clinical psychology that have demonstrated a close relation between episodic future thought and the ability to remember personal episodes from one's past. On the other hand, considerations of the role of abstracted (semantic) representations in episodic future thought have been noticeably absent in the literature. The final section of this article proposes that both episodic and semantic memory play an important role in the construction of episodic future thoughts and that their interaction in this process may be determined by the relative accessibility of information in memory.},
author = {Szpunar, Karl K},
doi = {10.1177/1745691610362350},
issn = {1745-6916},
journal = {Perspectives on psychological science : a journal of the Association for Psychological Science},
keywords = {Episodic future thought,Episodic memory,Mental simulation,Mental time travel},
number = {2},
pages = {142--162},
pmid = {26162121},
title = {{Episodic Future Thought: An Emerging Concept.}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77955847484{\{}{\&}{\}}partnerID=tZOtx3y1},
volume = {5},
year = {2010}
}
@article{Du2013,
abstract = {With the Internet growing exponentially, search engines are encountering unprecedented challenges. A focused search engine selectively seeks out web pages that are relevant to user topics. Determining the best strategy to utilize a focused search is a crucial and popular research topic. At present, the rank values of unvisited web pages are computed by considering the hyperlinks (as in the PageRank algorithm), a Vector Space Model and a combination of them, and not by considering the semantic relations between the user topic and unvisited web pages. In this paper, we propose a concept context graph to store the knowledge context based on the user's history of clicked web pages and to guide a focused crawler for the next crawling. The concept context graph provides a novel semantic ranking to guide the web crawler in order to retrieve highly relevant web pages on the user's topic. By computing the concept distance and concept similarity among the concepts of the concept context graph and by matching unvisited web pages with the concept context graph, we compute the rank values of the unvisited web pages to pick out the relevant hyperlinks. Additionally, we constitute the focused crawling system, and we retrieve the precision, recall, average harvest rate, and F-measure of our proposed approach, using Breadth First, Cosine Similarity, the Link Context Graph and the Relevancy Context Graph. The results show that our proposed method outperforms other methods. © 2013 Elsevier B.V. All rights reserved.},
author = {Du, YaJun and Pen, QiangQiang and Gao, ZhaoQiong},
doi = {10.1016/j.datak.2013.09.003},
issn = {0169023X},
journal = {Data {\{}{\&}{\}} Knowledge Engineering},
keywords = {Concept context graph,Focused crawling,Formal concept analysis,Information retrieval,Search engine,Web crawler,Web information systems},
pages = {75--93},
title = {{A topic-specific crawling strategy based on semantics similarity}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84889100636{\{}{\&}{\}}partnerID=tZOtx3y1},
volume = {88},
year = {2013}
}
@article{ISI:000253400700005,
author = {Theobald, Martin and Bast, Holger and Majumdar, Debapriyo and Schenkel, Ralf and Weikum, Gerhard},
doi = {10.1007/s00778-007-0072-z},
issn = {1066-8888},
journal = {VLDB JOURNAL},
number = {1},
pages = {81--115},
title = {{TopX: efficient and versatile top-k query processing for semistructured data}},
volume = {17},
year = {2008}
}
@misc{PrincipleLeastPrivilege,
abstract = {In information security, computer science, and other fields, the principle of least privilege (also known as the principle of minimal privilege or the principle of least authority) requires that in a particular abstraction layer of a computing environment, every module (such as a process, a user, or a program, depending on the subject) must be able to access only the information and resources that are necessary for its legitimate purpose.[1][2]},
author = {WikiPedia},
booktitle = {WikiPedia},
title = {{https://en.wikipedia.org/wiki/Principle{\{}{\_}{\}}of{\{}{\_}{\}}least{\{}{\_}{\}}privilege}},
url = {https://en.wikipedia.org/wiki/Principle{\{}{\_}{\}}of{\{}{\_}{\}}least{\{}{\_}{\}}privilege}
}
@misc{RoleBasedAccessControl,
abstract = {In computer systems security, role-based access control (RBAC)[1][2] is an approach to restricting system access to authorized users. It is used by the majority of enterprises with more than 500 employees,[3] and can implement mandatory access control (MAC) or discretionary access control (DAC). RBAC is sometimes referred to as role-based security. Role-Based-Access-Control (RBAC) is a policy neutral access control mechanism defined around roles and privileges. The components of RBAC such as role-permissions, user-role and role-role relationships make it simple to do user assignments. A study in NIST has demonstrated that RBAC addresses many needs of commercial and government organizations. RBAC can be used to facilitate administration of security in large organizations with hundreds of users and thousands of permissions. Although RBAC is different from MAC and DAC access control frameworks, it can enforce these policies without any complication. Its popularity is evident from the fact that many products and businesses are using it directly or indirectly.},
author = {WikiPedia},
booktitle = {WikiPedia},
title = {{https://en.wikipedia.org/wiki/Role-based{\{}{\_}{\}}access{\{}{\_}{\}}control}},
url = {https://en.wikipedia.org/wiki/Role-based{\{}{\_}{\}}access{\{}{\_}{\}}control}
}
@article{ISI:000295620300006,
abstract = {This article is centred on analysing the state of the art of the
conflation processes applied to geospatial databases (GDBs) from
heterogeneous sources. The term conflation is used to describe the
procedure for the integration of these different data, and conflation
methods play an important role in systems for updating GDBs, derivation
of new cartographic products, densification of digital elevation models,
automatic features extraction and so on. In this article we define
extensively each conflation process, its evaluation measures and its
main application problems and present a classification of all conflation
processes. Finally, we introduce a bibliography which the reader may
find useful to further explore the field. It tries to serve as a
starting point and direct the reader to characteristic research in this
area.},
address = {4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND},
author = {Ruiz, Juan J and Ariza, F Javier and Urena, Manuel A and Blazquez, Elidia B},
doi = {10.1080/13658816.2010.519707},
issn = {1365-8816},
journal = {INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE},
keywords = {conflation; data fusion; data integration; interop},
number = {9},
pages = {1439--1466},
publisher = {TAYLOR {\{}{\&}{\}} FRANCIS LTD},
title = {{Digital map conflation: a review of the process and a proposal for classification}},
type = {Review},
volume = {25},
year = {2011}
}
@article{Martinez-Cruz2011,
abstract = {Two main data models are currently used for representing knowledge and information in computer systems. Database models, especially relational databases, have been the leader in last few decades, enabling information to be efficiently stored and queried. On the other hand, ontologies have appeared as an alternative to databases in applications that require a more 'enriched' meaning. However, there is controversy regarding the best information modeling technique, as both models present similar characteristics. In this paper, we present a review of how ontologies and databases are related, of what their main differences are and of the mechanisms used to communicate with each other. © Springer Science+Business Media B.V. 2011.},
author = {Martinez-Cruz, Carmen and Blanco, Ignacio J and Vila, M Amparo},
doi = {10.1007/s10462-011-9251-9},
issn = {0269-2821},
journal = {Artificial Intelligence Review},
keywords = {Ontologies,Ontology-based databases,Relational databases},
number = {4},
pages = {271--290},
title = {{Ontologies versus relational databases: are they so different? A comparison}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84870244777{\{}{\&}{\}}partnerID=tZOtx3y1},
volume = {38},
year = {2011}
}

@article{Systems2010,
author = {Systems, Object-relational Database Management and Manage-, Relational Database},
file = {:home/spider77329/Documents/電腦信息處理/Object-Orieted{\_}database/ordb(1).pdf:pdf},
journal = {Management},
pages = {1--46},
title = {{Introduction to Object-Relational Database Development}},
url = {http://infolab.usc.edu/csci585/Spring2010/den{\_}ar/ordb.pdf},
year = {2010}
}

@misc{WiKiauthor2013,
abstract = {An object database (also object-oriented database management system - OODBMS) is a database management system in which information is represented in the form of objects as used in object-oriented programming. Object databases are different from relational databases which are table-oriented. Object-relational databases are a hybrid of both approaches. Object databases have been considered since the early 1980s.[2]},
author = {WiKi author},
pages = {1--5},
title = {{Object Database}},
url = {http://www.pcmag.com/encyclopedia/term/48213/object-database},
year = {2013}
}


