Abstract
The present paper concentrates on the issue of feature selection for unsuper-
vised word sense disambiguation (WSD) performed with an underlying Naïve Bayes model.
It introduces web N-gram features which, to our knowledge, are used for the ﬁrst time in
unsupervised WSD. While creating features from unlabeled data, we are “helping” a simple,
basic knowledge-lean disambiguation algorithm to significantly increase its accuracy as a
result of receiving easily obtainable knowledge. The performance of this method is com-
pared to that of others that rely on completely different feature sets. Test results concerning
nouns, adjectives and verbs show that web N-gram feature selection is a reliable alternative
to previously existing approaches, provided that a “quality list” of features, adapted to the
part of speech, is used.
